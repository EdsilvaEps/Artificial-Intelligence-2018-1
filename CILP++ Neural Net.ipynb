{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "from math import floor, ceil\n",
    "from pylab import rcParams\n",
    "from time import gmtime, strftime\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "#mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "\n",
    "\n",
    "\n",
    "# quantidade de exemplos que serão usados para treino\n",
    "tam_treino = 0.9 \n",
    "\n",
    "# abaixo vamos carregar nossos dados \n",
    "cl_positivas = pd.read_csv(\"trabFinal/dataset_ia_positivos_2.csv\", sep=\",\")\n",
    "cl_negativas = pd.read_csv(\"trabFinal/dataset_ia_negativos_2.csv\", sep=\",\")\n",
    "\n",
    "# juntando todos os nossos exemplos\n",
    "exemplos = cl_positivas.append(cl_negativas)\n",
    "\n",
    "# misturando os exemplos para motivos de treinamento\n",
    "exemplos = exemplos.sample(frac=1).reset_index(drop=True)\n",
    "#print(exemplos.shape)\n",
    "#print(exemplos[\"hd(X)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para codificar nossos exemplos e labels em vetores \"one-hot\"\n",
    "def encode(series):\n",
    "    return  pd.get_dummies(series.astype(str))\n",
    "\n",
    "exemplos_xplain = exemplos.drop('hd(X)',1)\n",
    "exemplos_y = encode(exemplos['hd(X)'])\n",
    "#exemplos_y = exemplos['hd(X)']\n",
    "#print(exemplos_xplain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 12)\n",
      "(5, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# separando nosso dataset em dados de treino e dados de teste\n",
    "cnt_treino = floor(exemplos_xplain.shape[0] * tam_treino)\n",
    "x_treino = exemplos_xplain.iloc[0:cnt_treino].values\n",
    "y_treino = exemplos_y.iloc[0:cnt_treino].values\n",
    "x_teste =  exemplos_xplain.iloc[cnt_treino:].values\n",
    "y_teste = exemplos_y.iloc[cnt_treino:].values\n",
    "\n",
    "# problemas com os tamanhos dos arrays\n",
    "print(x_teste.shape)\n",
    "print(y_teste.shape)\n",
    "\n",
    "# comparando com um dataset conhecido\n",
    "#tx,ty = mnist.train.next_batch(1)\n",
    "#print(ty.shape)\n",
    "#print(tx.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# camada 1 tem 1 neuron pra cada feature\n",
    "neurons_camada_1 = x_treino.shape[1]\n",
    "# camada 2 tem 1 neuron pra cada clausula\n",
    "neurons_camada_2 = exemplos.shape[0]\n",
    "neurons_saida = 2\n",
    "taxa_aprendizado = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, neurons_camada_1), name=\"X\")\n",
    "y = tf.placeholder(tf.int64,shape=(None,2), name=\"y\")\n",
    "\n",
    "\n",
    "# a rede neural é criada com os seguintes argumentos:\n",
    "with tf.name_scope(\"rede_neural\"):\n",
    "    camada_1 = fully_connected(X, neurons_camada_1, scope=\"camada_1\")\n",
    "    camada_2 = fully_connected(camada_1, neurons_camada_2, scope=\"camada_2\")\n",
    "    saida = fully_connected(camada_2, neurons_saida, scope=\"saida\", activation_fn=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computando o backprop na função de custo\n",
    "with tf.name_scope(\"funcao_de_custo\"):\n",
    "    \n",
    "    y_float = tf.cast(y, tf.float32)\n",
    "    sigmoidtropy = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        labels=y_float, logits=saida)\n",
    "    custo = tf.reduce_mean(sigmoidtropy, name=\"custo\")\n",
    "    \n",
    "    \n",
    "# configurando as operações de treino\n",
    "with tf.name_scope(\"treino\"):\n",
    "    otimizador = tf.train.GradientDescentOptimizer(taxa_aprendizado)\n",
    "    op_treino = otimizador.minimize(custo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 2)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "# avaliando a eficiencia da rede\n",
    "print(saida.shape)\n",
    "print(y[1].shape)\n",
    "#with tf.name_scope(\"eval\"):\n",
    "#    correto = tf.nn.in_top_k(saida, y[1], 1)\n",
    "#    eficacia = tf.reduce_mean(tf.cast(correto, tf.float32))\n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    previsao_correta = tf.equal(tf.argmax(saida,1), tf.argmax(y,1))\n",
    "    eficiencia = tf.reduce_mean(tf.cast(previsao_correta, \"float\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  - Eficiencia do treino:  1.0  - Eficiencia do teste: 0.2\n",
      "1  - Eficiencia do treino:  1.0  - Eficiencia do teste: 0.2\n",
      "2  - Eficiencia do treino:  1.0  - Eficiencia do teste: 0.2\n",
      "3  - Eficiencia do treino:  1.0  - Eficiencia do teste: 0.6\n",
      "4  - Eficiencia do treino:  1.0  - Eficiencia do teste: 0.6\n",
      "5  - Eficiencia do treino:  1.0  - Eficiencia do teste: 0.6\n",
      "6  - Eficiencia do treino:  1.0  - Eficiencia do teste: 0.8\n",
      "7  - Eficiencia do treino:  1.0  - Eficiencia do teste: 0.8\n",
      "8  - Eficiencia do treino:  1.0  - Eficiencia do teste: 0.8\n",
      "9  - Eficiencia do treino:  1.0  - Eficiencia do teste: 0.8\n",
      "10  - Eficiencia do treino:  1.0  - Eficiencia do teste: 0.8\n",
      "11  - Eficiencia do treino:  1.0  - Eficiencia do teste: 0.8\n",
      "12  - Eficiencia do treino:  1.0  - Eficiencia do teste: 0.8\n",
      "13  - Eficiencia do treino:  1.0  - Eficiencia do teste: 0.8\n",
      "14  - Eficiencia do treino:  1.0  - Eficiencia do teste: 0.8\n",
      "otimização completa!\n",
      "\n",
      "Entrada:  [[0 1 1 0 0 1 1 0 1 0 1 0]]\n",
      "Saída da rede:  [[ 0.60760462 -0.90563357]]  - Label:  [[1 0]]\n",
      "Predicao:  hd(X) falso  - Label:  hd(X) falso \n",
      "\n",
      "Entrada:  [[1 0 0 1 0 1 1 1 0 0 0 0]]\n",
      "Saída da rede:  [[-1.2520473   0.94565725]]  - Label:  [[1 0]]\n",
      "Predicao:  hd(X) verdadeiro  - Label:  hd(X) falso \n",
      "\n",
      "Entrada:  [[0 1 1 0 0 1 1 0 1 0 1 1]]\n",
      "Saída da rede:  [[ 0.69922864 -0.80386519]]  - Label:  [[1 0]]\n",
      "Predicao:  hd(X) falso  - Label:  hd(X) falso \n",
      "\n",
      "Entrada:  [[0 1 1 0 0 1 1 0 0 0 0 0]]\n",
      "Saída da rede:  [[ 0.54710376 -0.54683727]]  - Label:  [[1 0]]\n",
      "Predicao:  hd(X) falso  - Label:  hd(X) falso \n",
      "\n",
      "Entrada:  [[1 0 0 1 1 0 1 1 0 0 1 1]]\n",
      "Saída da rede:  [[-1.36420608  1.07734716]]  - Label:  [[0 1]]\n",
      "Predicao:  hd(X) verdadeiro  - Label:  hd(X) verdadeiro \n",
      "\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "n_epocas = 15\n",
    "tam_particao = 1 # usaremos gradient descent estocástico, pois temos poucos exemplos para treinar\n",
    "saver_path = \"./trabFinal/output/\" + strftime(\"%d-%m-%Y-%H:%M:%S/model\", gmtime())\n",
    "mostrar_dados = 1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoca in range(n_epocas):\n",
    "        particao_total = int(len(x_treino) / tam_particao)\n",
    "        x_parts = np.array_split(x_treino, particao_total)\n",
    "        y_parts = np.array_split(y_treino, particao_total)\n",
    "        for i in range(particao_total):\n",
    "            part_x, part_y = x_parts[i], y_parts[i]\n",
    "            sess.run(op_treino,feed_dict={X: part_x, y: part_y})\n",
    "            acc_treino = eficiencia.eval(feed_dict={X: part_x, y: part_y})\n",
    "            acc_teste = eficiencia.eval(feed_dict={X: x_teste, y: y_teste})\n",
    "        if epoca % mostrar_dados == 0:\n",
    "            print(epoca,\" - Eficiencia do treino: \" ,acc_treino, \" - Eficiencia do teste:\" ,acc_teste)        \n",
    "    print(\"otimização completa!\\n\")\n",
    "    #save_path = saver.save(sess, saver_path)\n",
    "    x_t = np.array_split(x_teste, 5)\n",
    "    y_t = np.array_split(y_teste, 5)\n",
    "    for k in range(5):\n",
    "            x_t2, y_t2 = x_t[k], y_t[k]\n",
    "            predicao = ''\n",
    "            label = ''\n",
    "            print(\"Entrada: \", x_t2)\n",
    "            #print(x_teste[k].shape)\n",
    "            #x = tf.placeholder(tf.float32, shape=(1, 12), name=\"X\")\n",
    "            if (y_t2.item(0) == 1): label = 'hd(X) falso'\n",
    "            elif(y_t2.item(1) == 1): label = 'hd(X) verdadeiro'\n",
    "            pred = saida.eval(feed_dict={X:x_t2})\n",
    "            if (pred.item(0) > pred.item(1)): predicao = 'hd(X) falso'\n",
    "            elif(pred.item(1) > pred.item(0)): predicao = 'hd(X) verdadeiro'\n",
    "            print(\"Saída da rede: \", saida.eval(feed_dict={X:x_t2}), \" - Label: \", y_t2)\n",
    "            print(\"Predicao: \", predicao, \" - Label: \", label,\"\\n\")\n",
    "    \n",
    "    \n",
    "    #previsao_correta = tf.equal(tf.argmax(saida,1), tf.argmax(y,1))\n",
    "    #eficiencia = tf.reduce_mean(tf.cast(previsao_correta, \"float\"))\n",
    "    #print(\"eficiencia: \", eficiencia.eval({X: x_teste, y: y_teste}))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrada:  [[0 1 1 0 0 1 1 0 1 0 1 0]]\n",
      "hd(X) falso\n",
      "Entrada:  [[1 0 0 1 0 1 1 1 0 0 0 0]]\n",
      "hd(X) falso\n",
      "Entrada:  [[0 1 1 0 0 1 1 0 1 0 1 1]]\n",
      "hd(X) falso\n",
      "Entrada:  [[0 1 1 0 0 1 1 0 0 0 0 0]]\n",
      "hd(X) falso\n",
      "Entrada:  [[1 0 0 1 1 0 1 1 0 0 1 1]]\n",
      "hd(X) verdadeiro\n"
     ]
    }
   ],
   "source": [
    "    x_t = np.array_split(x_teste, 5)\n",
    "    y_t = np.array_split(y_teste, 5)\n",
    "    for k in range(5):\n",
    "            x_t2, y_t2 = x_t[k], y_t[k]\n",
    "            predicao = ''\n",
    "            print(\"Entrada: \", x_t2)\n",
    "            \n",
    "            \n",
    "            #print(x_teste[k].shape)\n",
    "            #x = tf.placeholder(tf.float32, shape=(1, 12), name=\"X\")\n",
    "            if (y_t2.item(0) == 1): predicao = 'hd(X) falso'\n",
    "            elif(y_t2.item(1) == 1): predicao = 'hd(X) verdadeiro'\n",
    "            print(predicao)\n",
    "            #print(\"Saída da rede: \", saida.eval(feed_dict={X:x_t2}), \" - Label: \", y_t2, \" \", predicao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
